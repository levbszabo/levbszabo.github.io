## Implementation and Evaluation of the DANCER Framework for Academic Article Summarization

Joint Work: Aathira Manoj, Minji Kim

[Paper](/pdf/SummaryPaper.pdf)
<br>
[Powerpoint](/pdf/SummarySlides.pdf)
<br>
[Code](https://github.com/ls5122/ArxivSummary)

**Overview** Document summarization for academic articles is complicated by the document length, diversity and specialization of its vocabulary. The DANCER (Divide ANd ConquER) framework exploits the discourse structure of the document and uses sentence similarity to break a long document and its summary into multiple source-target pairs, which are used to train a summarization model. We assess the efficacy of the DANCER framework by using Pointer Generator as the summarization model and pairing it with different scoring metric (ROUGE-L, BLEU) for generating training samples. We evaluate its performance against a baseline model, which does not use DANCER. We use a subset of the publicly available arXiv dataset for our experiments.

### 1. Divide and Conquer

The Divide-ANd-ConquER (DANCER) framework exploits the discourse structure of long documents, by working on each section separately. It does so by decomposing the summary of the document into sections and pairing it with the appropriate sections in order to create distinct target summaries. A neural network model is then trained to learn to summarize each part of the document separately using these target summaries. Finally, the partial summaries generated by the model are then combined to produce a final complete summary

<br>

Academic articles are an ideal candidate for long document summarization because the paper abstract can serve as a label or a candidate summary for the paper. Additionally many papers follow a general structure with Introduction, Methods, Results and Conclusion being common sections in most articles. We can improve the summarization output and reduce computational costs by taking advantage of this common structure. 


<img src="images/dancer_training.JPG?raw=true"/>

<br>

<img src="images/dancer_testing.JPG?raw=true"/>


### 2. Problem Statement

Our goal is to evaluate and compare the performance of DANCER by using different scoring metrics for splitting the document summary into different sections. In particular, we use ROUGE-L and BLEU scores to generate the section-wise summaries from the main summary for training. We use the Pointer Generator, based on the sequence-to-sequence RNN paradigm, as the main summarization model. Finally, we compare the performance of the DANCER model with a baseline model, which also uses Pointer Generator, but does not split the main summary into section-wise summaries. We use a subset of a publicly available pre-processed ArXiv dataset for our experiments. The performance of different models is evaluated using ROUGE scores. 

A general outline of our approach is given below. 

* Use the DANCER method to generate training datasets using the ROUGE-LCS score and the BLEU-Corpus score. Generate a baseline dataset which does not use this approach.
* Train Pointer Generator Seq2Seq summarizer separately on all these datasets. 
* While testing, use the trained weights of the Pointer Generator model to generate section-wise summaries and concatenate them to generate the final summary .
* Evaluate the different models according to different ROUGE scores.



### 3. Data Analysis

English tweets are filtered and analyzed for positive, negative, neutral and mixed sentiment. On regular time intervals an AWS CloudWatch service initiates a serverless Lambda function to read unprocessed tweets from our MySQL database. Sentiment analysis and Keyword extraction are performed with AWS Comprehend and location matching using the Python geotext package. 

### 4. Data Visualization

Analytics regarding the breakdown of tweet sentiments, most common keywords and user locations is displayed as a dashboard using AWS QuickSight. Data is constantly refreshed to provide a real-time user experience. Below we have the sentiment breakdown across a variety of categories (Ex. Fear, Safety, Conspiracy). These results indicate the overall sentiment of specific topics in the Twitter space, we wish to use these as a stepping stone for future topic modelling approaches. Next we have the daily sentiment breakdown over the last 4 weeks, indicating any fluctuations in vaccine hesitancy. 

<img src="images/qs_2.JPG?raw=true"/>

<img src="images/qs_3.JPG?raw=true"/>
